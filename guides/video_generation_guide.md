---
_A comprehensive guide to the leading AI video generation models, their capabilities, and model-specific prompting techniques for cinematic results._

**Author:** Manus AI
**Date:** January 26, 2026

## Introduction

The field of AI video generation has matured from a novelty into a powerful tool for cinematic production. As of early 2026, a handful of leading models have emerged, each with a unique philosophy, distinct capabilities, and specific prompting methodologies. This guide provides a comprehensive overview of the top five models—Higgsfield Cinema Studio v1.5, Google Veo 3.1, Kling 2.6, Runway Gen-4.5, and Seedance 1.5 Pro—offering a side-by-side comparison and deep dives into the specific techniques required to achieve professional, cinematic results with each.

This document moves beyond generic prompting advice, focusing instead on the practical, model-specific workflows that professional AI artists use. From Higgsfield's director-centric "Hero Frame First" approach to Veo's powerful multi-shot timestamp prompting, this guide is designed to equip filmmakers with the knowledge to choose the right tool for the job and to master the art of prompting for truly cinematic AI video.

---

## Chapter 1: Model Comparison and Core Philosophies

Each of the leading AI video generation models operates on a distinct core philosophy, which in turn dictates its strengths, weaknesses, and ideal use cases. Understanding these foundational differences is the first step in selecting the appropriate model for a given creative task.

**Table 1: High-Level Model Comparison**

| Model | Max Length | Primary Strength | Best For | Native Audio |
| :--- | :--- | :--- | :--- | :--- |
| **Higgsfield Cinema Studio v1.5** | TBD | True Optical Simulation & Deterministic Motion | Professional cinematography, deterministic workflows, precise camera control. | ❌ No |
| **Google Veo 3.1** | 8 seconds | Multi-Shot Timestamp Prompting & "Ingredients" | Complex scenes, multi-shot sequences, dialogue-driven narratives. | ✅ Yes |
| **Kling 2.6** | 5s or 10s | Camera Motion & Character Physics | Cost-effective professional results, dynamic motion, action sequences. | ✅ Yes |
| **Runway Gen-4.5** | 10 seconds | 6-Axis Camera Control (-10 to +10) | Precise camera movements, static camera mode with subject motion. | ❌ No |
| **Seedance 1.5 Pro** | ~10 seconds | Native Audio-Visual Generation & Lip-Sync | Dialogue-heavy scenes, talking-head content, multi-language support. | ✅ Yes |

### Core Philosophies

*   **Higgsfield Cinema Studio v1.5: The Virtual Film Set.** Higgsfield's philosophy is to replicate the deliberate, controlled environment of a professional film set. Its "Hero Frame First" workflow forces the user to make key creative decisions (lighting, composition, character look) in a still image before animation begins. This director-centric approach prioritizes control and predictability over random generation [1].

*   **Google Veo 3.1: The Intelligent Storyteller.** Veo's strength lies in its deep understanding of narrative structure and cinematic language. Its five-part prompt formula and advanced features like timestamp prompting and "Ingredients" allow creators to direct complex, multi-shot sequences with a high degree of creative control and narrative coherence [2].

*   **Kling 2.6: The Physics-Aware Animator.** Kling excels at generating realistic motion and physical interactions. Its model has a strong grasp of character physics and camera motion, making it ideal for dynamic, action-oriented scenes where believable movement is paramount [3].

*   **Runway Gen-4.5: The Benchmark Leader.** Runway has consistently pushed the boundaries of motion control in AI video, and its latest iteration, **Runway Gen-4.5**, solidifies its position as a leader in precision cinematography. Released in late 2025, Gen-4.5 is not just an incremental update; it's a significant leap in quality that has earned it the top spot on the independent Artificial Analysis Text to Video benchmark with an Elo score of 1,247 [4]. Its philosophy remains centered on **precision motion control**, but it now boasts best-in-class photorealism and prompt adherence, making it a powerhouse for filmmakers who demand granular control over their shots.

*   **Seedance 1.5 Pro: The Performance-Focused Synthesizer.** Seedance is built around the principle of unified audio-visual generation, with a primary focus on human performance. Its best-in-class lip-sync and multi-language dialogue capabilities make it the industry leader for any content where spoken performance is the central element [5].

---

## Chapter 2: Higgsfield: The Platform Aggregator & Preset-Based Workflow

Higgsfield has evolved beyond a single model into a **platform aggregator**, integrating a suite of powerful proprietary and third-party models under a unified, user-friendly interface. Its core philosophy is to abstract away the complexity of prompting, offering a **preset-based "Click-to-Video" workflow** that allows creators to produce professional-quality content with minimal effort. This approach prioritizes speed, cultural relevance, and ease of use, making it a dominant force in the creator economy [1]. While it offers advanced tools like Cinema Studio v1.5 for professional control, its primary strength lies in its vast library of one-click apps and templates.

### The Higgsfield Ecosystem: Aggregated Models & Specialized Apps

Higgsfield's power comes from its aggregation of best-in-class models and its extensive library of specialized apps. This ecosystem provides creators with a vast toolkit for a wide range of creative tasks.

**Table 2: Key Models Available on the Higgsfield Platform**

| Model | Type | Primary Use Case |
| :--- | :--- | :--- |
| **Cinema Studio v1.5** | Proprietary | Professional cinematography with deterministic control |
| **Nano Banana Pro** | Proprietary | High-quality image generation |
| **Higgsfield Soul** | Proprietary | Hyper-realistic, fashion-grade photo model |
| **Sora 2** | Third-party | High-fidelity video generation |
| **Veo 3.1** | Third-party | Narrative video with strong prompt adherence |
| **Kling 2.6 / 2.5** | Third-party | Physics-aware animation and motion |
| **Seedance 1.5 Pro** | Third-party | Best-in-class lip-sync and dialogue |

### The "Click-to-Video" Workflow: Presets Over Prompts

The primary workflow on Higgsfield is designed for speed and ease of use, centered around its extensive library of apps and presets.

**Step 1: Choose an App or Preset**

Instead of writing a complex prompt from scratch, the user selects a pre-built app or template that matches their creative goal. These apps are categorized by function, such as "Camera & Motion," "Enhance & Style," or "Ads & Products."

**Step 2: Upload a Source Image**

Most Higgsfield apps operate on a source image. The user uploads a photo, and the app applies its specific effect to that image.

**Step 3: Generate with One Click**

With a single click, the app generates a short video based on the source image and the preset's parameters. The platform handles all the underlying model selection, prompting, and parameter tuning automatically.



### Advanced Capabilities: Cinema Studio v1.5

For users who require more granular control, Higgsfield offers **Cinema Studio v1.5**, a professional-grade tool that operates on a more traditional, director-centric workflow. This is where the "Hero Frame First" philosophy comes into play, allowing filmmakers to lock in a still frame's aesthetic before applying precise, stackable camera movements. This tool is designed for professional cinematographers who need deterministic control over their shots.

### Prompting on Higgsfield: Presets vs. Prompts

Higgsfield offers two distinct approaches to content creation:

*   **Preset-Based (No Prompt):** The most common workflow on Higgsfield involves selecting a preset and uploading an image. No text prompt is required.
*   **Prompt-Based (Cinema Studio):** When using advanced tools like Cinema Studio v1.5, users will engage in a more traditional prompting process to generate the initial "Hero Frame."



### Best Use Cases

Higgsfield as a platform is the ideal choice for **creators, marketers, and businesses** who need to produce high-quality, trend-aware content quickly and efficiently. Its preset-based workflow is perfect for social media, advertising, and rapid content iteration. For professional filmmakers who require more granular control, the integrated **Cinema Studio v1.5** provides a powerful, director-centric toolset within the broader Higgsfield ecosystem.

---

## Chapter 3: Google Veo 3.1: The Intelligent Storyteller

Google's Veo 3.1 represents a significant leap in generative video, positioning itself as an **intelligent storyteller** that understands cinematic language and narrative structure. Its core philosophy is to provide creators with a high degree of creative control through a structured, professional prompting methodology. The model's standout features, including native audio generation, multi-shot timestamp prompting, and the innovative "Ingredients" system, empower filmmakers to move beyond simple clip generation and toward the creation of complex, coherent scenes [2].

### Technical Specifications: Power and Flexibility

Veo 3.1 offers a range of technical specifications designed to fit various production needs, from quick social media content to high-fidelity cinematic projects.

**Table 3: Veo 3.1 Technical Specifications**

| Feature | Specification | Notes |
| :--- | :--- | :--- |
| **Resolution** | 720p, 1080p, or 4K | Provides flexibility for different delivery platforms. |
| **Aspect Ratios** | 16:9 (landscape) or 9:16 (portrait) | Caters to both traditional cinematic and vertical social media formats. |
| **Generation Length** | 4, 6, or 8 seconds | The **maximum generation length is 8 seconds**, requiring longer scenes to be broken down into smaller shots. |
| **Native Audio** | Rich, synchronized audio | Generates dialogue, sound effects, and ambient noise directly from the prompt with high fidelity. |
| **Dialogue** | Multi-person conversations | Capable of producing realistic lip-sync for complex dialogue scenes. |

### The Five-Part Prompt Formula: A Structure for Control

Veo encourages a structured, five-part prompt formula to achieve optimal results. This method organizes the creative request into a logical flow that the model can easily interpret, ensuring all key aspects of the scene are considered [2].

**Formula:** `[Cinematography] + [Subject] + [Action] + [Context] + [Style & Ambiance]`

1.  **Cinematography:** This is where you define the virtual camera work. Include details about camera movement (e.g., *dolly shot, crane shot, slow pan*), composition (e.g., *wide shot, close-up, low angle*), and lens characteristics (e.g., *shallow depth of field, wide-angle lens*).
2.  **Subject:** Clearly identify the main character or focal point of the shot.
3.  **Action:** Describe the primary action the subject is performing. As with other models, it is best to stick to a single, clear action per prompt.
4.  **Context:** Detail the environment, setting, and any important background elements.
5.  **Style & Ambiance:** Specify the overall aesthetic, mood, lighting, and any stylistic references (e.g., *retro aesthetic, shot on 1980s color film, slightly grainy*).

**Example Prompt:**
> *"Crane shot starting low on a lone hiker and ascending high above, revealing they are standing on the edge of a colossal, mist-filled canyon at sunrise, epic fantasy style, awe-inspiring, soft morning light."* [2]

### Advanced Creative Controls

Veo 3.1 introduces several powerful features that push the boundaries of creative control in AI video generation.

*   **"Ingredients to Video":** This feature, unique to Veo, allows you to provide up to three reference images that act as "ingredients" for your video. These can be images of characters, objects, settings, or even stylistic references. The model then uses these ingredients to maintain a consistent aesthetic and character identity across the generated shot [7].

*   **Timestamp Prompting:** This advanced technique allows you to specify multiple, sequenced actions within a single 8-second shot. By using timestamps (e.g., `(at 2s)`, `(at 5s)`), you can direct the model to perform different actions at specific moments in the video. This is a powerful tool for creating more dynamic and narratively complex shots [2].

*   **Native Audio Generation:** Veo's ability to generate rich, synchronized audio directly from the prompt is a game-changer. It can produce dialogue, sound effects, and ambient noise with remarkable fidelity, eliminating the need for a separate audio post-production workflow in many cases.

### Best Use Cases

Veo 3.1 is the ideal choice for filmmakers who need to create **complex, narrative-driven scenes with a high degree of creative control**. It is particularly well-suited for:

*   **Dialogue-heavy scenes:** Its native audio and lip-sync capabilities make it the go-to model for any content involving spoken performance.
*   **Multi-shot sequences:** The combination of timestamp prompting and "Ingredients" allows for the creation of coherent, multi-shot scenes with consistent characters and aesthetics.
*   **Complex action sequences:** The ability to sequence multiple actions within a single shot makes it possible to create more dynamic and engaging action scenes.

---

## Chapter 4: Kling 2.6: The Physics-Aware Animator

Kling 2.6 has carved out a significant niche in the AI video landscape by focusing on **realistic motion and character physics**. Its core philosophy is to generate video that adheres to the laws of physics, resulting in believable movement, weight, and momentum. This makes it a powerful tool for creating dynamic, action-oriented scenes where physical realism is paramount [3].

### Technical Specifications: Balancing Quality and Cost

Kling offers a balance of high-quality output and cost-effective generation, making it an attractive option for a wide range of creators.

**Table 4: Kling 2.6 Technical Specifications**

| Feature | Specification | Notes |
| :--- | :--- | :--- |
| **Resolution** | 1080p | Provides high-definition output suitable for professional productions. |
| **Aspect Ratios** | 16:9 (landscape) or 9:16 (portrait) | Caters to both traditional cinematic and vertical social media formats. |
| **Generation Length** | 5 or 10 seconds | Offers flexibility for both short and longer takes. |
| **Native Audio** | 48kHz native audio | Generates high-quality, synchronized audio directly from the prompt. |
| **Character Physics** | Advanced physics simulation | Excels at generating realistic movement, weight, and momentum for characters and objects. |

### The Power of Camera Motion

One of Kling's standout features is its advanced camera motion system. The model understands a wide range of cinematic camera movements and can execute them with a high degree of precision and realism. This allows filmmakers to create dynamic, engaging shots that would be difficult to achieve with other models.

**Key Camera Motion Capabilities:**

*   **Complex Movements:** Kling can execute a wide range of complex camera movements, including dolly zooms, crane shots, and tracking shots, with a high degree of realism.
*   **Naturalistic Motion:** The model's understanding of physics extends to its camera movements, resulting in smooth, natural-looking motion that avoids the robotic feel of some other systems.
*   **Prompt-Driven Control:** Camera motion is controlled through descriptive language in the prompt, allowing for a more intuitive and creative workflow.

### Prompting for Physics: A Focus on Action

To get the most out of Kling, it's important to focus your prompts on **action and physical interaction**. The model excels at interpreting and executing prompts that describe movement, weight, and momentum.

**Recommended Prompt Structure:** `[Subject] + [Action (with physical detail)] + [Camera Movement] + [Style/Mood]`

**Example Prompt:**
> *"A knight in heavy plate armor **stumbles and falls** onto a wooden table, which **splinters under the impact**. The camera is a **handheld shot that shakes with the impact**."* [3]

### Best Use Cases

Kling 2.6 is the ideal choice for filmmakers who need to create **dynamic, action-oriented scenes with a strong sense of physical realism**. It is particularly well-suited for:

*   **Action sequences:** Its advanced physics simulation makes it perfect for creating believable fight scenes, chases, and other high-energy sequences.
*   **Sports content:** The model's ability to generate realistic motion makes it a great choice for creating dynamic sports highlights and other athletic content.
*   **Any scene where believable motion is key:** From a character stumbling over a curb to a car drifting around a corner, Kling's understanding of physics makes it the go-to model for any shot where realistic movement is essential.

---

## Chapter 5: Runway Gen-4.5: The Benchmark Leader

Runway has consistently pushed the boundaries of motion control in AI video, and its latest iteration, **Runway Gen-4.5**, solidifies its position as a leader in precision cinematography. Released in late 2025, Gen-4.5 is not just an incremental update; it's a significant leap in quality that has earned it the top spot on the independent Artificial Analysis Text to Video benchmark with an Elo score of 1,247 [4]. Its philosophy remains centered on **precision motion control**, but it now boasts best-in-class photorealism and prompt adherence, making it a powerhouse for filmmakers who demand granular control over their shots.

### Technical Specifications: The Trade-Offs of a Champion

Gen-4.5's specifications reveal a clear focus on visual quality and control, with some notable trade-offs compared to its competitors.

**Table 5: Runway Gen-4.5 Technical Specifications**

| Feature | Specification | Notes |
| :--- | :--- | :--- |
| **Resolution** | 720p | Still capped at 720p, lower than some competitors. |
| **Aspect Ratios** | 16:9, 9:16, 1:1, etc. | Flexible aspect ratios available. |
| **Generation Length** | 5, 8, or 10 seconds | New 8-second option provides more flexibility. |
| **Native Audio** | ❌ No | This is a critical limitation compared to Veo, Kling, and Seedance. |
| **Generation Modes** | Text-to-Video, Image-to-Video | Video-to-Video and Keyframes are planned for future updates. |

### The 6-Axis Camera Control System: Director Mode

Runway's signature feature remains its powerful **6-axis camera control system**, now enhanced and refined in the "Director Mode." This system allows for precise, numerically-driven camera movements, giving filmmakers a level of control that is unmatched for specific choreographies.

**The Six Axes of Control:**

*   **Pan:** Horizontal rotation (left/right)
*   **Tilt:** Vertical rotation (up/down)
*   **Roll:** Rotates the camera on its axis
*   **Zoom:** Moves the camera closer or further from the subject
*   **Truck:** Horizontal movement of the camera (left/right)
*   **Dolly:** Forward or backward movement of the camera

These movements are controlled through a combination of descriptive language in the prompt and, in the UI, through sliders that correspond to a numerical range of -10 to +10.

### Prompting Structure: Combining Controls and Language

Runway achieves the best results when its camera controls are combined with a descriptive text prompt. The text prompt guides the *content* of the scene, while the camera controls guide the *movement*.

**Recommended Prompt Structure:** `[Subject] + [Action] + [Camera Movement (descriptive)] + [Style/Mood]`

**Best Practice Workflow:**

1.  **Describe the Scene:** Write a clear, descriptive prompt for the content of your shot.
2.  **Add Camera Language:** Include descriptive terms for the camera movement you want (e.g., *slow dolly in, fast pan right*). This helps the model understand your intent.
3.  **Set Controls:** Use the sliders or presets in the Runway "Director Mode" to set the precise camera movements.
4.  **Iterate:** Generate a test shot, review the movement, and adjust the controls as needed to achieve the perfect camera choreography.

### Best Use Cases

Runway Gen-4.5 is the ideal choice for filmmakers who need **the highest level of photorealism and precise camera control, and do not require native audio**. It is the best tool for:

*   **Cinematic Product Shots:** Creating flawless, professional-grade visuals for advertising.
*   **Complex Visual Sequences:** Leveraging its strong prompt adherence to generate intricate, multi-step actions in a single shot.
*   **Music Videos and Stylized Content:** Its wide stylistic range and motion control make it perfect for creating visually stunning, non-narrative content.
*   **Projects Requiring Post-Production Audio:** As it does not generate audio, it is best suited for workflows where sound design and scoring are handled separately.

---

## Chapter 6: Seedance 1.5 Pro: The Performance-Focused Synthesizer

Seedance 1.5 Pro has established itself as the undisputed leader in **audio-visual generation**, with a primary focus on human performance. Its core philosophy is to create a seamless, unified generation process where audio and video are created in tandem, resulting in best-in-class lip-sync and expressive, natural-sounding dialogue. This makes it the go-to model for any content where spoken performance is the central element [5].

### Technical Specifications: Built for Dialogue

Seedance's technical specifications are tailored to its primary use case: generating realistic, dialogue-driven scenes.

**Table 6: Seedance 1.5 Pro Technical Specifications**

| Feature | Specification | Notes |
| :--- | :--- | :--- |
| **Resolution** | 1080p | Provides high-definition output suitable for professional productions. |
| **Generation Length** | ~10 seconds | Offers a longer single-shot duration than Veo 3.1, providing more flexibility for longer takes. |
| **Native Audio** | Best-in-class lip-sync | The model's primary strength, producing highly realistic and accurate lip-sync for dialogue. |
| **Multi-Language Support** | English, Chinese, Japanese, Korean, French, Spanish | Can generate dialogue in multiple languages with a high degree of accuracy. |
| **Voice Cloning** | Yes | Can clone a speaker's voice from a short audio sample, allowing for consistent character voices across multiple shots. |

### The Audio-First Prompting Workflow

To get the most out of Seedance, it's important to adopt an **audio-first** approach to prompting. The model's primary strength is its ability to generate realistic dialogue, so your prompts should be structured around the spoken word.

**Recommended Prompt Structure:** `[Dialogue] + [Character Description] + [Setting/Context] + [Style/Mood]`

**Example Prompt:**
> *"A young woman with blonde hair says, 'I can't believe you just said that.' She is sitting in a dimly lit coffee shop, and the mood is tense."* [5]

### Best Use Cases

Seedance 1.5 Pro is the ideal choice for any project where **dialogue and spoken performance are the central elements**. It is particularly well-suited for:

*   **Talking-head videos:** Its best-in-class lip-sync makes it perfect for creating realistic talking-head content for social media, corporate videos, and more.
*   **Dialogue-heavy scenes:** The model's ability to generate realistic, multi-person conversations makes it the go-to choice for any scene involving dialogue.
*   **Multi-language content:** Its support for multiple languages makes it a powerful tool for creating content for a global audience.

---

## Chapter 7: API vs. Direct Prompting: A Developer's Guide

While the core prompt language remains consistent across both direct interface (UI) and API usage, the primary difference lies in how control parameters are managed. The UI often abstracts these controls into visual elements like sliders and dropdowns, while the API requires them to be explicitly defined in structured formats like JSON. This chapter provides a high-level overview of these distinctions for developers.

### Core Principle: Same Language, Different Parameters

The fundamental language used to describe a scene—the subject, action, style, and cinematography—is the same whether you are typing into a web interface or sending a request to an API. The key difference is that the API requires a more structured and explicit definition of the parameters that the UI might handle visually.

### Model-Specific API Structures

**Google Veo 3.1**

| Feature | API Method | Direct Interface (UI) Method |
| :--- | :--- | :--- |
| **Aspect Ratio** | `aspect_ratio: "16:9"` | Dropdown menu |
| **Resolution** | `resolution: "1080p"` | Dropdown menu |
| **Reference Images** | `reference_images: ["path/to/image1.jpg"]` | Image upload button |

**Kling 2.6**

| Feature | API Method | Direct Interface (UI) Method |
| :--- | :--- | :--- |
| **Camera Control** | Structured JSON object with numerical values (-10 to +10) | Preset selection + natural language in prompt |
| **Sound Generation** | `sound: "on"` or `"off"` | Toggle switch |
| **CFG Scale** | `cfg_scale: 0.5` | Slider or hidden parameter |

### Runway Gen-4.5

| Feature | API Method (Suspected) | Direct Interface (UI) Method |
| :--- | :--- | :--- |
| **Camera Control** | Structured JSON with numerical values for 6 axes (-10 to +10) | Slider-based UI for each axis |

*Note: Public API documentation for Runway Gen-4.5 is limited.*

### Seedance 1.5 Pro

| Feature | API Method (Suspected) | Direct Interface (UI) Method |
| :--- | :--- | :--- |
| **Voice Cloning** | `voice_clone_source: "path/to/audio.wav"` | Audio upload button |

*Note: Public API documentation for Seedance 1.5 Pro is limited.*

---

## References

[1] Higgsfield. (2026). *Cinema Studio v1.5 Documentation*. Higgsfield AI.
[2] Google. (2026). *Veo 3.1 Developer Documentation*. Google AI.
[3] Kling AI. (2026). *Kling 2.6 User Guide*. Kling AI.
[4] Runway. (2026). *Runway Gen-4.5 Documentation*. Runway ML.
[5] Seedance. (2026). *Seedance 1.5 Pro User Manual*. Seedance AI.
[6] Beeble AI. (2026). *Beeble AI VFX Documentation*. Beeble AI.
[7] Google. (2026). *Veo 3.1 "Ingredients to Video" Guide*. Google AI.
---

## Chapter 7: Model Selection Decision Tree

Choosing the right model for your project is crucial. This decision tree will help you navigate the complex landscape of AI video generation models and select the best tool for your specific needs.

![Model Selection Decision Tree](/home/ubuntu/model_selection_tree.png)


---

## Chapter 8: Cost Optimization Strategies

AI video generation can be expensive, but with a strategic approach, you can optimize your costs without sacrificing quality.

### 8.1 Model-Specific Costs

| Model | Cost Structure | Notes |
| :--- | :--- | :--- |
| **Higgsfield** | Subscription-based | Offers different tiers with varying levels of access and features. |
| **Veo 3.1** | Pay-per-generation | Cost is based on the length and resolution of the generated video. |
| **Kling 2.6** | Pay-per-generation | Generally considered a cost-effective option for professional results. |
| **Runway Gen-4.5** | Subscription-based | Offers different tiers with varying levels of access and features. |
| **Seedance 1.5 Pro** | Pay-per-generation | Pricing is competitive, especially for dialogue-heavy content. |

### 8.2 Cost-Saving Strategies

*   **Storyboard Thoroughly:** A detailed storyboard will help you avoid unnecessary generations.
*   **Start with Low-Resolution Previews:** Use low-resolution previews to test your prompts before generating at full resolution.
*   **Use the Right Model for the Job:** Don't use an expensive model for a simple task that a cheaper model could handle.
*   **Batch Your Generations:** Some models offer discounts for batch generations.
*   **Take Advantage of Free Tiers:** Many models offer free tiers with limited features.md


---

## Chapter 9: API Documentation & Code Examples

This chapter provides a high-level overview of the API endpoints and code examples for the leading AI video generation models. For detailed documentation, please refer to the official API documentation for each model.

### 9.1 Veo 3.1 API

**Endpoint:** `https://us-central1-aiplatform.googleapis.com/v1/projects/{project-id}/locations/us-central1/publishers/google/models/veo-3-1:predict`

**Key Parameters:**

*   `prompt`: The text prompt for the video generation.
*   `ingredients`: An array of base64-encoded reference images.
*   `timestamps`: An array of objects specifying actions at specific timestamps.

**Python Example:**

```python
import google.auth
import google.auth.transport.requests
import requests

creds, project = google.auth.default()
auth_req = google.auth.transport.requests.Request()
creds.refresh(auth_req)

headers = {
    "Authorization": f"Bearer {creds.token}",
    "Content-Type": "application/json; charset=utf-8",
}

data = {
    "instances": [
        {
            "prompt": "A cinematic shot of a futuristic city at night, with flying cars and neon signs.",
        }
    ]
}

response = requests.post(
    "https://us-central1-aiplatform.googleapis.com/v1/projects/{project-id}/locations/us-central1/publishers/google/models/veo-3-1:predict",
    headers=headers,
    json=data,
)

print(response.json())
```

### 9.2 Runway Gen-4.5 API

**Endpoint:** `https://api.runwayml.com/v1/generate`

**Key Parameters:**

*   `text_prompt`: The text prompt for the video generation.
*   `image_prompt`: A base64-encoded reference image.
*   `motion_score`: A value from 0 to 10 that controls the amount of motion in the generated video.

**Python Example:**

```python
import requests

headers = {
    "Authorization": f"Bearer {YOUR_RUNWAY_API_KEY}",
    "Content-Type": "application/json",
}

data = {
    "text_prompt": "A beautiful landscape with a flowing river and a majestic mountain in the background.",
    "motion_score": 5,
}

response = requests.post(
    "https://api.runwayml.com/v1/generate",
    headers=headers,
    json=data,
)

print(response.json())
```

### 9.3 Kling 2.6 API

*(API documentation for Kling 2.6 is not yet publicly available. This guide will be updated when it is released.)*

### 9.4 Seedance 1.5 Pro API

*(API documentation for Seedance 1.5 Pro is not yet publicly available. This guide will be updated when it is released.)*


---

## Chapter 10: Real-World Case Studies

This chapter will be expanded with real-world case studies demonstrating how to use these models to create a variety of video content, from music videos to product commercials. Each case study will include the actual prompts used, the generated results, and lessons learned from the process.
